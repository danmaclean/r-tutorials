---
title: "Gene expression Databases and Expression Analysis"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(gradethis)
gradethis_setup()
knitr::opts_chunk$set(echo = FALSE)
```

## Aims

The aim of this tutorial is to examine how we can use public genomics databases to retrieve RNAseq data that describes expression of genes. We shall then work through an example in which we carry out expression estimates for the data we downloaded. 

## Browsing for expression data

The Gene Expression Omnibus is a great place to search for gene expression data. There is a general 'advanced' search page at [https://www.ncbi.nlm.nih.gov/gds/advanced/](https://www.ncbi.nlm.nih.gov/gds/advanced/) which allows you to build a complex search. We'll skip past that and jump straight to a given GEO accession. This is simply because we want to use a small dataset that will run quickly.

We'll use a simple _E.coli_ dataset that examines gene expression at different points of the growth phase in culture, once at 8h (mid logarithmic growth) and once at 14h (late logarithmic growth).

Use the GEO Advanced Search to find records relating to the accession `GSE77674`

```{r geoacc}
question(
  "How many samples are available for the Series accession record we used?",
  answer("1"), answer("2", correct = TRUE), answer("3")
)
```

Now that we found the record for the accession we can see the metadata about the experiment submitted, in particular the sample information. 

```{r geoacc-1}
question(
  "What sequencing machine was used?",
  answer("454"), answer("Illumina Hiseq", correct = TRUE), answer("Nanopore")
)
```

```{r geoacc-2}
question(
  "What sequencing machine was used?",
  answer("454"), answer("Illumina Hiseq", correct = TRUE), answer("Nanopore")
)
```

```{r geoacc-3}
question(
  "Which sample accession describes the 8h reads?",
  answer("GSM2055958", correct=TRUE), answer("GSM2055959"), answer("	SRP069289")
)
```

```{r, taxid-1}
question(
  "What _strain_ of _E.coli_ was used?",
  answer("DH5a"), answer("W3110"), answer("K12f", correct=TRUE)
)
```

```{r,taxid-2}
question(
  "Use the NCBI taxonomy browswer to find the taxonomy ID _E.coli_ K12 at the strain level. Which is it?",
  answer("83333", correct=TRUE), answer("51145"), answer("329")
)
```

In GEO/SRA 'runs' describe a single run of the sequencing machine and usually describe a single set of reads (sometimes paired).

```{r geoacc-4}
question(
  "How many replicates are done for each sample?",
  answer("1", correct=TRUE), answer("2"), answer("3")
)
```

```{r geoacc-5}
question(
  "What is the run id for the 8h sample? (You may need to browse some of the links to find this out)",
  answer("SRR3144643",), answer("SRX1560781"), answer("SRR3144708", correct=TRUE)
)
```

```{r geoacc-6}
question(
  "What is the run id for the 14h sample? (You may need to browse some of the links to find this out)",
  answer("SRR3144643", correct=TRUE), answer("SRX1560781"), answer("SRR3144708")
)
```

Now that we have identified the run accessions we are able to download the actual reads to work on them.  

## Downloading data with SRAtools

The web page provides a download button for the data, and while for this small transcriptome with small files (relatively speaking) downloading through the browser might work, we can do this better using the `SRAtools` package on the command-line.

Start up your terminal program. We can use the `SRAtools` package to retrieve data in one steps. We use the `fastq-dump` command to prepare the data and download it to an uncompressed text file in fastq format. Note that often you will not want uncompressed data as raw read data can be very large. You can check the SRAtools manuals for more flexible download options [here](https://www.ncbi.nlm.nih.gov/sra/docs/sradownload/#download-sequence-data-files-usi)

Download the reads for each run e.g - with ID `SRR3144643` as follows:

```
fastq-dump SRR3144643
```

Make sure you download runs for both 8h and 14h samples.

```{r dload-1}
question(
  "How many reads were downloaded for 14h?",
  answer("9"), answer("9,339,062", correct=TRUE), answer("212,897")
)
```

```{r dload-2}
question(
  "How many reads were downloaded for 8h?",
  answer("10,691,872",correct=TRUE), answer("9,339,062", correct=TRUE), answer("3,144,643")
)
```

Now that we have the reads, we need the definitive sequences of the transcripts. This will allow us to align the reads to the transcripts, count how many reads align to each and get a measure of the abundance of each transcript in the sample. 

Databases like EnsemblBacteria ([bacteria.ensembl.org](bacteria.ensembl.org)) hold the resources we need. Go there and use the `Search for a genome` box to find `Escherichia coli`. 

```{r, ensembl-1}
question(
  "How many E.coli genomes are found?",
  answer("25"), answer("about 1,200", correct=TRUE), answer("about 31000")
)
```

Use the filter to find the genomes coming from the correct strain with the taxid you found.

```{r, ensembl-2}
question(
  "How many E.coli K12 genomes are found?",
  answer("about 12",correct=TRUE), answer("about 1,200"), answer("about 31000")
)
```

There are so many results because numerous different sequencing projects have used this organism so there are lots of assemblies of the strains and substrains of _E.coli_. For our purposes we can select any of the assemblies but the differences may be important for your real lab work. Click the link in the `species` column of the top result (with assembly acession `gca_004802935` to go to the page for that assembly. 

In the `Gene annotation` box, select the `FASTA` link in the `Download genes` section to open up a link to the files containing the transcript sequences. The sequences of the transcripts are in a folder called `cds` (for coding sequence). Open that and copy the file called `Escherichia_coli_k_12_gca_004802935.ASM480293v1.cds.all.fa.gz` to the same place you downloaded the reads to. Using drag and drop is fine, as this file should be very small.

The file extension `.gz` indicates this file is compressed with `gzip`. On some systems you can uncompress it with a double click of the icon or you can do it on the command line like this

```
gunzip Escherichia_coli_k_12_gca_004802935.ASM480293v1.cds.all.fa.gz
```


## Estimating transcript counts with _kallisto_

We can now perform a quantification of the transcripts using the reads. We only have one sample for each time point, which is highly unusual but is enough for demonstration purposes. 

We'll use the `kallisto` quantifier [https://pachterlab.github.io/kallisto/about](https://pachterlab.github.io/kallisto/about). The program works in two steps, we first make an index of our transcript sequences and then we `pseudoalign` reads to the index to work out how many reads come from each transcript. 

### Building the index

The index needs only be built once, we can do that with this command line

```
kallisto index -i ecoli_index.idx Escherichia_coli_k_12_gca_004802935.ASM480293v1.cds.all.fa
```

which only takes a moment for this small genome. The command indicates that we want to `index` and what our index should be called with `-i`, our output index is therefore `ecoli_index.idx`. The final argument is the file of transcript sequences that we wish to use. 


### Quantification

Now we can estimate the transcript abundances, once for each file of sample reads. We treat the file as if single-ended, though better quantification can be achieved if you have paired end info.

For the 8h reads we can use this command line

```
kallisto quant -i ecoli_index.idx -o 8h -b 100 --single -l 180 -s 20 SRR3144708.fastq
```

which runs `quant` using index `-i ecoli_index.idx`, the results will be output to a folder called `8h` (`-o 8h`). One hundred bootstrap repetitions are performed (`-b 100`), single end mode is used (`--single`) and the length (`-l 180`) and SD of fragments (`-s 20`), is given. 

The corresponding command line for the 14h reads is as follows

```
kallisto quant -i ecoli_index.idx -o 14h -b 100 --single -l 180 -s 20 SRR3144643.fastq
```

### Examining abundances.tsv

The transcript abundances are placed in the output folder inside a file called `abundances.tsv`. Check it like this (remembering to use `q` to quit `less`)

```
head 8h/abundance.tsv
```

part of which looks like this

```
target_id   length    eff_length    est_counts    tpm
THH56748    1158      979           41            2.28274
THH56492    933	      754           173           12.5063
THH56493    756	      577           546           51.5789
THH56494    1248	    1069          10            0.509891
```


We can see the target ID (the transcript name) and the estimates, resulting in the tags per million `tpm` at the end of each row. The `tpm` is our final expression estimate for the transcripts and is a value we can build into bigger exploratory analyses. 

## Wrap up and next steps

This tutorial is focussed on using databases to find reads and quantify transcript abundances and we've done that successfully. The process of RNAseq and transcriptome analysis once we've got those reads is much more involved. Analysing the resulting transcript counts to make valid and useful biological inferences is a very different topic that takes in statistics and data visualisation. There are a great number of introductory tutorials on all aspects of expression analysis all over the web. One good starting place is with `kallisto`'s companion tool, `sleuth` which will allow you to perform differential analysis and some important QC measures. Try here [https://pachterlab.github.io/sleuth_walkthroughs/trapnell/analysis.html](https://pachterlab.github.io/sleuth_walkthroughs/trapnell/analysis.html) for a good introduction to `sleuth`.

